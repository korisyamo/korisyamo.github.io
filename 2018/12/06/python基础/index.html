<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="python爬虫," />





  <link rel="alternate" href="/atom.xml" title="第一口浮生茶" type="application/atom+xml" />






<meta name="description" content="#　python辅助工具　pycharm的安装 链接：https://blog.csdn.net/gaojinwei22/article/details/79699998 学生或者教师可以免费使用 不过每一年需要复审一次。需要自己的校内邮箱或者国际邮箱。 链接：https://blog.csdn.net/m0_37693335/article/details/81104408  python基础语">
<meta name="keywords" content="python爬虫">
<meta property="og:type" content="article">
<meta property="og:title" content="python基础">
<meta property="og:url" content="http://yoursite.com/2018/12/06/python基础/index.html">
<meta property="og:site_name" content="第一口浮生茶">
<meta property="og:description" content="#　python辅助工具　pycharm的安装 链接：https://blog.csdn.net/gaojinwei22/article/details/79699998 学生或者教师可以免费使用 不过每一年需要复审一次。需要自己的校内邮箱或者国际邮箱。 链接：https://blog.csdn.net/m0_37693335/article/details/81104408  python基础语">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://img-blog.csdn.net/20181006135621655?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181006140448129?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181006141233100?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181006141538847?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181006142633106?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181007122204577?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181007122723114?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181011190823135?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181011191521993?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181011192104933?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdn.net/20181006145928788?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:updated_time" content="2018-12-06T11:59:28.100Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python基础">
<meta name="twitter:description" content="#　python辅助工具　pycharm的安装 链接：https://blog.csdn.net/gaojinwei22/article/details/79699998 学生或者教师可以免费使用 不过每一年需要复审一次。需要自己的校内邮箱或者国际邮箱。 链接：https://blog.csdn.net/m0_37693335/article/details/81104408  python基础语">
<meta name="twitter:image" content="https://img-blog.csdn.net/20181006135621655?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/12/06/python基础/"/>





  <title>python基础 | 第一口浮生茶</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
   <div class="headband">
  <a href="https://korisyamo.github.io/" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; left: 0; transform: scale(-1, 1);" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style></a>
  </div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">第一口浮生茶</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/06/python基础/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="koris">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="第一口浮生茶">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">python基础</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-06T19:17:20+08:00">
                2018-12-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">python爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>#　python辅助工具　pycharm的安装</p>
<p>链接：<a href="https://blog.csdn.net/gaojinwei22/article/details/79699998" target="_blank" rel="noopener">https://blog.csdn.net/gaojinwei22/article/details/79699998</a></p>
<p>学生或者教师可以免费使用 不过每一年需要复审一次。需要自己的校内邮箱或者国际邮箱。</p>
<p>链接：<a href="https://blog.csdn.net/m0_37693335/article/details/81104408" target="_blank" rel="noopener">https://blog.csdn.net/m0_37693335/article/details/81104408</a></p>
<hr>
<h1 id="python基础语法用例-python-代码求list集合交并差、随机生成字符串"><a href="#python基础语法用例-python-代码求list集合交并差、随机生成字符串" class="headerlink" title="python基础语法用例　python 代码求list集合交并差、随机生成字符串"></a>python基础语法用例　python 代码求list集合交并差、随机生成字符串</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line"> </span><br><span class="line">print(&quot;随机生成n个0-30随机数的数组：&quot;)</span><br><span class="line">def randlist(n):</span><br><span class="line">    return [random.randint(0,30) for i in range(n)]</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">def main():</span><br><span class="line">    a=randlist(10)</span><br><span class="line">    b=randlist(20)</span><br><span class="line"> </span><br><span class="line">    print(a)</span><br><span class="line">    print(b)</span><br><span class="line"> </span><br><span class="line">    print(&quot;去重并集：&quot;)</span><br><span class="line">    c=list(set(a).union(set(b)))</span><br><span class="line">    print(c)</span><br><span class="line"> </span><br><span class="line">    print(&quot;去重交集：&quot;)</span><br><span class="line">    d=list(set(a).intersection(set(c)))</span><br><span class="line">    print(d)</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">main()</span><br><span class="line"> </span><br><span class="line">s=random.randint(65,90)</span><br><span class="line">r=chr(s)</span><br><span class="line">print(r)</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="python基础知识"><a href="#python基础知识" class="headerlink" title="python基础知识"></a>python基础知识</h1><h2 id="python-requests库的７个主要方法"><a href="#python-requests库的７个主要方法" class="headerlink" title="python requests库的７个主要方法"></a>python requests库的７个主要方法</h2><p><img src="https://img-blog.csdn.net/20181006135621655?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"><br>Request库的get（）方法：</p>
<p>最通常的方法是通过r=request.get（url）构造一个向服务器请求资源的url对象。</p>
<p>这个对象是Request库内部生成的。</p>
<p>这时候的r返回的是一个包含服务器资源的Response对象。包含从服务器返回的所有的相关资源。</p>
<p>url是什么？</p>
<p>url是通过http协议存取资源的一个路径，它就像我们电脑里面的一个文件的路径一样。</p>
<p>这个函数完整的使用方法有三个参数：<br><img src="https://img-blog.csdn.net/20181006140448129?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p>
<p><strong>其实也可以看它的源代码就可以发现 其实它是通过调用request方法来实现的。也就是说，Request库里面有7个常用方法，get只是其中一个，而除了里面的request方法，其他六个都是通过调用request方法来实现的，实际上都是request方法在实现。其他的类似的方法只是为了大家编写程序更方便。</strong></p>
<p>Request库的两个重要对象 :Response对象和Request对象。<br><img src="https://img-blog.csdn.net/20181006141233100?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p>
<p>Response对象常用的属性：<br><img src="https://img-blog.csdn.net/20181006141538847?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p>
<p>还有要注意分析网站的编码：<br><img src="https://img-blog.csdn.net/20181006142633106?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p>
<p>一个访问baidu的实例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">print(&apos;访问baidu网站 获取Response对象&apos;)</span><br><span class="line">r = requests.get(&quot;http://www.baidu.com&quot;)</span><br><span class="line">print(r.status_code)</span><br><span class="line">print(r.encoding)</span><br><span class="line">print(r.apparent_encoding)</span><br><span class="line">print(&apos;将对象编码转换成UTF-8编码并打印出来&apos;)</span><br><span class="line">r.encoding = &apos;utf-8&apos;</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure></p>
<p>输出为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">访问baidu网站 获取Response对象</span><br><span class="line">200</span><br><span class="line">ISO-8859-1</span><br><span class="line">utf-8</span><br><span class="line">将对象编码转换成UTF-8编码并打印出来</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt; &lt;div class=head_wrapper&gt; &lt;div class=s_form&gt; &lt;div class=s_form_wrapper&gt; &lt;div id=lg&gt; &lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129&gt; &lt;/div&gt; &lt;form id=form name=f action=//www.baidu.com/s class=fm&gt; &lt;input type=hidden name=bdorz_come value=1&gt; &lt;input type=hidden name=ie value=utf-8&gt; &lt;input type=hidden name=f value=8&gt; &lt;input type=hidden name=rsv_bp value=1&gt; &lt;input type=hidden name=rsv_idx value=1&gt; &lt;input type=hidden name=tn value=baidu&gt;&lt;span class=&quot;bg s_ipt_wr&quot;&gt;&lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus&gt;&lt;/span&gt;&lt;span class=&quot;bg s_btn_wr&quot;&gt;&lt;input type=submit id=su value=百度一下 class=&quot;bg s_btn&quot;&gt;&lt;/span&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=u1&gt; &lt;a href=http://news.baidu.com name=tj_trnews class=mnav&gt;新闻&lt;/a&gt; &lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav&gt;hao123&lt;/a&gt; &lt;a href=http://map.baidu.com name=tj_trmap class=mnav&gt;地图&lt;/a&gt; &lt;a href=http://v.baidu.com name=tj_trvideo class=mnav&gt;视频&lt;/a&gt; &lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav&gt;贴吧&lt;/a&gt; &lt;noscript&gt; &lt;a href=http://www.baidu.com/bdorz/login.gif?login&amp;amp;tpl=mn&amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb&gt;登录&lt;/a&gt; &lt;/noscript&gt; &lt;script&gt;document.write(&apos;&lt;a href=&quot;http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=&apos;+ encodeURIComponent(window.location.href+ (window.location.search === &quot;&quot; ? &quot;?&quot; : &quot;&amp;&quot;)+ &quot;bdorz_come=1&quot;)+ &apos;&quot; name=&quot;tj_login&quot; class=&quot;lb&quot;&gt;登录&lt;/a&gt;&apos;);&lt;/script&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;更多产品&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a href=http://home.baidu.com&gt;关于百度&lt;/a&gt; &lt;a href=http://ir.baidu.com&gt;About Baidu&lt;/a&gt; &lt;/p&gt; &lt;p id=cp&gt;&amp;copy;2017&amp;nbsp;Baidu&amp;nbsp;&lt;a href=http://www.baidu.com/duty/&gt;使用百度前必读&lt;/a&gt;&amp;nbsp; &lt;a href=http://jianyi.baidu.com/ class=cp-feedback&gt;意见反馈&lt;/a&gt;&amp;nbsp;京ICP证030173号&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="python网络爬虫的Robots协议"><a href="#python网络爬虫的Robots协议" class="headerlink" title="python网络爬虫的Ｒobots协议"></a>python网络爬虫的Ｒobots协议</h2><p>网络爬虫的尺寸大致分为3种：<br><img src="https://img-blog.csdn.net/20181007122204577?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p>
<p>而第一种大致占到了90%。由于网络爬虫的存在，服务器会因为网络爬虫造成很大的资源开销，比如一个普通人一定时间内访问上十次，而爬虫可能会访问十万次或者百万次。如果一个服务器性能较差，可能会承受不来这个规模的访问。因此网络上对爬虫有一定的制约，对于一些不友好的爬虫，甚至可能会涉及到触犯到法律。</p>
<p>现在一般的网站都会对爬虫做出限制，大致分为两种：<br><img src="https://img-blog.csdn.net/20181007122723114?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="iamge"></p>
<p>现在说一下第二种，Robots（Robots Exclusion Standard ）协议，也叫机器人协议。</p>
<p>作用：告知爬虫网页上哪些内容可以爬取，哪些不行。</p>
<p>形式：在网站根目录下放置robots.txt文件。</p>
<p>比如我们用代码去获取京东的robots协议：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import  requests</span><br><span class="line"> </span><br><span class="line">def getHTTPXML( url ):</span><br><span class="line">    try:</span><br><span class="line">        r = requests.get(url, timeout = 30)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        return r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;产生异常&quot;</span><br><span class="line"> </span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    url = &quot;http://www.jd.com/robots.txt&quot;</span><br><span class="line">    print(getHTTPXML(url))</span><br></pre></td></tr></table></figure></p>
<p>爬取下来的robots协议为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">User-agent: * </span><br><span class="line">Disallow: /?* </span><br><span class="line">Disallow: /pop/*.html </span><br><span class="line">Disallow: /pinpai/*.html?* </span><br><span class="line">User-agent: EtaoSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: HuihuiSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: GwdangSpider </span><br><span class="line">Disallow: / </span><br><span class="line">User-agent: WochachaSpider </span><br><span class="line">Disallow: /</span><br></pre></td></tr></table></figure></p>
<p><strong>它是什么意思呢，我们来分析一下。</strong></p>
<p>第一行*表示所有的，也就是说，对于所有的网络爬虫，它都定义为User-agent </p>
<p>意思就是说对于所有的网络爬虫，都应该遵守这个协议。</p>
<p>第二行什么意思呢？disallow表示不允许，？后面是*，表示？后面所有的东西，也就是说，它不允许任何爬虫访问任何以？开头的路径。</p>
<p>第三行表示任何爬虫都不允许访问pop/开头的路径。</p>
<p>第四行同理，符合这类的路径也不允许访问。</p>
<p>后面的又写了四个爬虫，EtaoSpider等等</p>
<p>他们被禁止的是根目录。这四种爬虫不允许爬取京东的任何资源。</p>
<p>也就是说这四种爬虫被京东定义为恶意爬虫，非法的获取过京东的资源，所以京东不允许这四类爬虫获取京东的任何资源了。</p>
<p>对于不遵守robots协议的爬虫，可能会存在法律风险。</p>
<hr>
<p>所以大家也看到了，robots协议就是通过User-agent 和 disallow这两个基本语法来告知所有爬虫它内部能访问的权限。</p>
<p>有了这个的话，就相当于告知所有爬虫应该去遵守这个网站的规范，相当于制定了一个准则。</p>
<p>不同的网站会有不同的robots协议，我们也可以看看其他网站的robots协议。</p>
<p>来看一下百度的robots协议：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line">User-agent: Baiduspider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Googlebot</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: MSNBot</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Baiduspider-image</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: YoudaoBot</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Sogou web spider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Sogou inst spider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Sogou spider2</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Sogou blog</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Sogou News Spider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Sogou Orion spider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: ChinasoSpider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: Sosospider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">User-agent: yisouspider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: EasouSpider</span><br><span class="line">Disallow: /baidu</span><br><span class="line">Disallow: /s?</span><br><span class="line">Disallow: /shifen/</span><br><span class="line">Disallow: /homepage/</span><br><span class="line">Disallow: /cpro</span><br><span class="line">Disallow: /ulink?</span><br><span class="line">Disallow: /link?</span><br><span class="line">Disallow: /home/news/data/</span><br><span class="line"> </span><br><span class="line">User-agent: *</span><br><span class="line">Disallow: /</span><br></pre></td></tr></table></figure></p>
<p>qq的robots协议：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Disallow:  </span><br><span class="line">Sitemap: http://www.qq.com/sitemap_index.xml</span><br></pre></td></tr></table></figure></p>
<p>新浪新闻的robots协议：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Disallow: /wap/</span><br><span class="line">Disallow: /iframe/</span><br><span class="line">Disallow: /temp/</span><br></pre></td></tr></table></figure></p>
<p><strong>不是所有网站都有robots协议，比如国家教育部的网站就没有robots协议，它就默认为所有网络爬虫都可以无限制的去爬取这个网站。</strong></p>
<hr>
<h2 id="python学习使用正则表达式-re库"><a href="#python学习使用正则表达式-re库" class="headerlink" title="python学习使用正则表达式(re库)"></a>python学习使用正则表达式(re库)</h2><p><strong>re库是python中自带的一个库，不需要外部导入。</strong></p>
<p><strong>它主要是支持正则表达式匹配。</strong></p>
<p>下面来说一下其主要功能函数：</p>
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">re.search()</td>
<td style="text-align:center">在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象。</td>
</tr>
<tr>
<td style="text-align:center">re.match()</td>
<td style="text-align:center">在一个字符串的开始位置起匹配表达式，返回match对象</td>
</tr>
<tr>
<td style="text-align:center">re.findall()</td>
<td style="text-align:center">搜索字符串，以列表类型返回全部能匹配的子串</td>
</tr>
<tr>
<td style="text-align:center">re.split()</td>
<td style="text-align:center">将一个字符串按照正则表达式的匹配结果进行分割，返回列表类型</td>
</tr>
<tr>
<td style="text-align:center">re.finditer()</td>
<td style="text-align:center">搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象</td>
</tr>
<tr>
<td style="text-align:center">re.sub()</td>
<td style="text-align:center">在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td>
</tr>
</tbody>
</table>
<p>正则表达式使用标记：</p>
<table>
<thead>
<tr>
<th style="text-align:center">常用标记</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">re.I  re.IGNORECASE</td>
<td style="text-align:center">忽略正则表达式的大小写 【A-Z】能够匹配小写字符</td>
</tr>
<tr>
<td style="text-align:center">re.M re.MULITILINE</td>
<td style="text-align:center">正则表达式中的^操作符能够将给定字符串的每行当作匹配开始</td>
</tr>
<tr>
<td style="text-align:center">re.S re.DOTALL</td>
<td style="text-align:center">正则表达式中的.操作符能够匹配所有字符，默认匹配除换行外的所有字符</td>
</tr>
</tbody>
</table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">match = re.search(r&apos;[1-9]\d&#123;5&#125;&apos;,&apos;BIT 100081&apos;)</span><br><span class="line">if match:</span><br><span class="line">    print(match.group(0))</span><br><span class="line"></span><br><span class="line">match2 = re.match(r&apos;[1-9]\d&#123;5&#125;&apos;,&apos;100081 BIT&apos;)</span><br><span class="line">if match2:</span><br><span class="line">    print(match2.group(0))</span><br><span class="line"></span><br><span class="line">match3 = re.match(r&apos;[1-9]\d&#123;5&#125;&apos;, &apos;BIT 100081&apos;)</span><br><span class="line">if match3:</span><br><span class="line">    print(match3.group(0))</span><br></pre></td></tr></table></figure>
<p>返回结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">100081</span><br><span class="line">100081</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></p>
<p>第三个不返回 结果 因为他是从第一个开始匹配 很明显第一个字母B和它的正则表达式不匹配，所以结果为空，那么if判断之后 将不会输出。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">ls = re.findall(r&apos;[1-9]\d&#123;5&#125;&apos;, &apos;BIT100081 FSABIT100085&apos;)</span><br><span class="line">if ls:</span><br><span class="line">    print(ls)</span><br><span class="line"></span><br><span class="line">ls = re.split(r&apos;[1-9]\d&#123;5&#125;&apos;, &apos;BIT100081 FSABIT100085&apos;)</span><br><span class="line">if ls:</span><br><span class="line">    print(ls)</span><br><span class="line">ls = re.split(r&apos;[1-9]\d&#123;5&#125;&apos;, &apos;BIT100081 FSABIT100085&apos;,maxsplit=1)</span><br><span class="line">if ls:</span><br><span class="line">    print(ls)</span><br><span class="line"></span><br><span class="line">for m in re.finditer(r&apos;[1-9]\d&#123;5&#125;&apos;,&apos;BIT100081 FSABIT100085&apos;):</span><br><span class="line">    if m:</span><br><span class="line">        print(m.group(0))</span><br><span class="line"></span><br><span class="line">ls = re.sub(r&apos;[1-9]\d&#123;5&#125;&apos;, &apos;:zipcode&apos;, &apos;BIT100081 FSABIT100085&apos;)</span><br><span class="line">print(ls)</span><br></pre></td></tr></table></figure>
<p>输出结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[&apos;100081&apos;, &apos;100085&apos;]</span><br><span class="line">[&apos;BIT&apos;, &apos; FSABIT&apos;, &apos;&apos;]</span><br><span class="line">[&apos;BIT&apos;, &apos; FSABIT100085&apos;]</span><br><span class="line">100081</span><br><span class="line">100085</span><br><span class="line">BIT:zipcode FSABIT:zipcode</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="python理解beautiful-soup库的基本元素"><a href="#python理解beautiful-soup库的基本元素" class="headerlink" title="python理解beautiful soup库的基本元素"></a>python理解beautiful soup库的基本元素</h2><p>理解Beautiful Soup的基本元素是理解Beautiful Soup库的基础。</p>
<p>首先我们说明一下Beautiful Soup库能干什么。</p>
<p>我们以打开html文件为例。</p>
<p>任何一组html文件它都是以尖括号为组的标签组织起来的。而这些标签建立起来的东西我们称之为标签树。</p>
<p>而Beautiful Soup库是解析，遍历，维护标签树的功能库。</p>
<p>标签的具体格式如图：<br><img src="https://img-blog.csdn.net/20181011190823135?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="iamge"></p>
<p>Beautiful Soup库常见的四种解析器：<br><img src="https://img-blog.csdn.net/20181011191521993?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p>
<p>现在我们来介绍一下Beautiful Soup库的基本元素：<br><img src="https://img-blog.csdn.net/20181011192104933?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="iamge"></p>
<p>下面我们来介绍一下获得tag标签的相关方法</p>
<p>任何语法标签都可以用soup.tag方法访问获得，比如我们要获取某个界面的a标签：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">r = requests.get(&quot;http://python123.io/ws/demo.html&quot;)</span><br><span class="line">demo = r.text</span><br><span class="line">from bs4 import  BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(demo, &quot;html.parser&quot;)</span><br><span class="line">tag = soup.a</span><br><span class="line">print(tag)</span><br></pre></td></tr></table></figure></p>
<p>输出为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;a class=&quot;py1&quot; href=&quot;http://www.icourse163.org/course/BIT-268001&quot; id=&quot;link1&quot;&gt;Basic Python&lt;/a&gt;</span><br></pre></td></tr></table></figure></p>
<p>但是当存在多个标签的时候，我们用soup.tag只能返回其中第一个。</p>
<p>name表示获取相关标签的名字，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">r = requests.get(&quot;http://python123.io/ws/demo.html&quot;)</span><br><span class="line">demo = r.text</span><br><span class="line">from bs4 import  BeautifulSoup</span><br><span class="line">soup = BeautifulSoup(demo, &quot;html.parser&quot;)</span><br><span class="line">print(soup.a.parent.name)</span><br><span class="line">print(soup.a.parent.parent.name)</span><br></pre></td></tr></table></figure></p>
<p>输出为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p</span><br><span class="line">body</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="python实现多线程并发执行-join函数"><a href="#python实现多线程并发执行-join函数" class="headerlink" title="python实现多线程并发执行(join函数)"></a>python实现多线程并发执行(join函数)</h2><p>主线程启动一个子线程t并等到t线程结束后才执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line">def reading():</span><br><span class="line">    for i in range(5):</span><br><span class="line">        print(&quot;reading&quot;, i)</span><br><span class="line">        time.sleep(1)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">t = threading.Thread(target = reading)</span><br><span class="line">t.setDaemon(True)</span><br><span class="line">t.start()</span><br><span class="line">t.join()</span><br><span class="line">print(&quot;The End&quot;)</span><br></pre></td></tr></table></figure></p>
<p>运行结果为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">reading 0</span><br><span class="line">reading 1</span><br><span class="line">reading 2</span><br><span class="line">reading 3</span><br><span class="line">reading 4</span><br><span class="line">The End</span><br></pre></td></tr></table></figure></p>
<p>由此可见主线程启动子线程t执行reading函数 t.join阻塞主线程，一直等到t线程执行完毕后才结束t线程结束才执行主线程输出the end。</p>
<p>在子线程启动另外一个子线程，并等待子线程结束后才继续执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line">def reading():</span><br><span class="line">    for i in range(5):</span><br><span class="line">        print(&quot;reading&quot;, i)</span><br><span class="line">        time.sleep(1)</span><br><span class="line"> </span><br><span class="line">def test():</span><br><span class="line">    r = threading.Thread(target=reading)</span><br><span class="line">    r.setDaemon(True)</span><br><span class="line">    r.start()</span><br><span class="line">    r.join()</span><br><span class="line">    print(&quot;test end&quot;)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">t = threading.Thread(target = test)</span><br><span class="line">t.setDaemon(True)</span><br><span class="line">t.start()</span><br><span class="line">t.join()</span><br><span class="line">print(&quot;The End&quot;)</span><br></pre></td></tr></table></figure></p>
<p>运行结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">reading 0</span><br><span class="line">reading 1</span><br><span class="line">reading 2</span><br><span class="line">reading 3</span><br><span class="line">reading 4</span><br><span class="line">test end</span><br><span class="line">The End</span><br></pre></td></tr></table></figure></p>
<p>由此可见主线程启动t线程后t.join会等待t线程结束，在test中再次启动r子线程，r子线程加入r.join而阻塞t线程，知道r进程结束，然后才显示test end，然后t线程结束再次结束t.join。主线程显示The End 结束。</p>
<h1 id="python爬虫实例"><a href="#python爬虫实例" class="headerlink" title="python爬虫实例"></a>python爬虫实例</h1><h2 id="python简单爬取网页的通用代码框架"><a href="#python简单爬取网页的通用代码框架" class="headerlink" title="python简单爬取网页的通用代码框架"></a>python简单爬取网页的通用代码框架</h2><p>爬取网页的通用代码框架就是一组代码</p>
<p>它可以准确的 可靠的爬取网页上的内容。</p>
<p>但是这样的语句不是一定成立的，因为网络连接有风险。</p>
<p>常见的异常有：<br><img src="https://img-blog.csdn.net/20181006145928788?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tfa29yaXM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="image"></p>
<p>而raise_for_status方法可以返回所引发的httperror异常。</p>
<p>爬取网页的框架代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">def getHTMLText(url):</span><br><span class="line">    try:</span><br><span class="line">        r = requests.get(url, timeout=30)</span><br><span class="line">        r.raise_for_status()  #如果状态不是200 引发http error异常</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        return r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;产生异常&quot;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    url = &quot;http://www.baidu.com&quot;</span><br><span class="line">    print(getHTMLText(url))</span><br></pre></td></tr></table></figure></p>
<h2 id="python简单图片爬取框架"><a href="#python简单图片爬取框架" class="headerlink" title="python简单图片爬取框架"></a>python简单图片爬取框架</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import os</span><br><span class="line">url = &quot;http://image.nationalgeographic.com.cn/2017/0211/20170211061910157.jpg&quot;</span><br><span class="line">root = &quot;D://pics//&quot;</span><br><span class="line">path = root + url.split(&apos;/&apos;)[-1]</span><br><span class="line">try:</span><br><span class="line">    if not os.path.exists(root):</span><br><span class="line">        os.mkdir(root)</span><br><span class="line">    if not os.path.exists(path):</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        with open(path, &apos;wb&apos;) as f:</span><br><span class="line">            f.write(r.content)</span><br><span class="line">            f.close()</span><br><span class="line">            print(&quot;文件保存成功&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;文件已经存在&quot;)</span><br><span class="line">except:</span><br><span class="line">    print(&quot;爬取失败&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="python爬取中国大学排名"><a href="#python爬取中国大学排名" class="headerlink" title="python爬取中国大学排名"></a>python爬取中国大学排名</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import bs4</span><br><span class="line">def gegHTMLText(url):</span><br><span class="line">    try:</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        return r.text</span><br><span class="line">    except:</span><br><span class="line">        return &quot;&quot;</span><br><span class="line"> </span><br><span class="line">def fillUnivList(ulist,html):</span><br><span class="line">    soup = BeautifulSoup(html, &quot;html.parser&quot;)</span><br><span class="line">    for tr in soup.find(&apos;tbody&apos;).children: #采用循环查找html文本中的tbody标签并且将它的孩子children做一个遍历</span><br><span class="line">        if isinstance(tr, bs4.element.Tag): #检测tr标签的标签类型 如果不是bs4库里面定义的Tag类型 则过滤掉</span><br><span class="line">            tds = tr(&apos;td&apos;)</span><br><span class="line">            ulist.append([tds[0].string, tds[1].string, tds[2].string])</span><br><span class="line"> </span><br><span class="line">def printUnivList(ulist,num):</span><br><span class="line">    print(&quot;&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;&quot;.format(&quot;排名&quot;, &quot;学校&quot;, &quot;分数&quot;)) #表头信息的打印</span><br><span class="line">    for i in range(num):</span><br><span class="line">        u = ulist[i]</span><br><span class="line">        print(&quot;&#123;:^10&#125;\t&#123;:^6&#125;\t&#123;:^10&#125;&quot;.format(u[0], u[1], u[2]))</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">def main():</span><br><span class="line">    uinfo = []</span><br><span class="line">    url = &quot;http://www.zuihaodaxue.cn/zuihaodaxuepaiming2016.html&quot;</span><br><span class="line">    html = gegHTMLText(url)</span><br><span class="line">    fillUnivList(uinfo, html)</span><br><span class="line">    printUnivList(uinfo, 20)</span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<h2 id="python爬取豆瓣影评"><a href="#python爬取豆瓣影评" class="headerlink" title="python爬取豆瓣影评"></a>python爬取豆瓣影评</h2><p>看的别人的代码 爬取某部影片的影评 没有模拟登录只能爬6页<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"># -*- encoding:utf-8 -*-</span><br><span class="line"> </span><br><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import re</span><br><span class="line">import random</span><br><span class="line">import  io</span><br><span class="line">import  sys</span><br><span class="line">import time</span><br><span class="line"> </span><br><span class="line"># 使用session来保存登陆信息</span><br><span class="line">s = requests.session()</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"># 获取动态ip，防止ip被封</span><br><span class="line">def get_ip_list(url, headers):</span><br><span class="line">    web_data = requests.get(url, headers=headers)</span><br><span class="line">    soup = BeautifulSoup(web_data.text, &apos;lxml&apos;)</span><br><span class="line">    ips = soup.find_all(&apos;tr&apos;)</span><br><span class="line">    ip_list = []</span><br><span class="line">    for i in range(1, len(ips)):</span><br><span class="line">        ip_info = ips[i]</span><br><span class="line">        tds = ip_info.find_all(&apos;td&apos;)</span><br><span class="line">        ip_list.append(tds[1].text + &apos;:&apos; + tds[2].text)</span><br><span class="line">    return ip_list</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"># 随机从动态ip链表中选择一条ip</span><br><span class="line">def get_random_ip(ip_list):</span><br><span class="line">    proxy_list = []</span><br><span class="line">    for ip in ip_list:</span><br><span class="line">        proxy_list.append(&apos;http://&apos; + ip)</span><br><span class="line">    proxy_ip = random.choice(proxy_list)</span><br><span class="line">    proxies = &#123;&apos;http&apos;: proxy_ip&#125;</span><br><span class="line">    return proxies</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"># 获取评论内容和下一页链接</span><br><span class="line">def get_data(html):</span><br><span class="line">    soup = BeautifulSoup(html, &quot;lxml&quot;)</span><br><span class="line">    comment_list = soup.select(&apos;.comment &gt; p&apos;)</span><br><span class="line">    next_page = soup.select(&apos;.next&apos;)[0].get(&apos;href&apos;)</span><br><span class="line">    return comment_list, next_page</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding=&apos;utf8&apos;)</span><br><span class="line">    absolute = &apos;https://movie.douban.com/subject/26322642/comments&apos;</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.89 Safari/537.36&apos;&#125;</span><br><span class="line">    loginUrl = &apos;https://www.douban.com/accounts/login?source=movie&apos;</span><br><span class="line">    formData = &#123;</span><br><span class="line">        &quot;redir&quot;: &quot;https://movie.douban.com/subject/26322642/comments?start=201&amp;limit=20&amp;sort=new_score&amp;status=P&amp;percent_type=&quot;,</span><br><span class="line">        &quot;form_email&quot;: &quot;www.1239198605@qq.com&quot;,</span><br><span class="line">        &quot;form_password&quot;: &quot;yyf15997588668&quot;,</span><br><span class="line">        &quot;login&quot;: u&apos;登录&apos;</span><br><span class="line">    &#125;</span><br><span class="line">    # 获取动态ip</span><br><span class="line">    url = &apos;http://www.xicidaili.com/nn/&apos;</span><br><span class="line">    ip_list = get_ip_list(url, headers=headers)</span><br><span class="line">    proxies = get_random_ip(ip_list)</span><br><span class="line"> </span><br><span class="line">    current_page = absolute</span><br><span class="line">    next_page = &quot;&quot;</span><br><span class="line">    comment_list = []</span><br><span class="line">    temp_list = []</span><br><span class="line">    num = 0</span><br><span class="line">    ans = 0</span><br><span class="line">    while (1):</span><br><span class="line">        ans+=1</span><br><span class="line">        print(&quot;爬取第&quot; + str(ans) + &quot;页&quot;)</span><br><span class="line">        time.sleep(5)</span><br><span class="line">        html = s.get(current_page,  headers=headers, proxies=proxies).content</span><br><span class="line">        temp_list, next_page = get_data(html)</span><br><span class="line"> </span><br><span class="line">        if ans is 7:</span><br><span class="line">            break</span><br><span class="line">        current_page = absolute + next_page</span><br><span class="line">        comment_list = comment_list + temp_list</span><br><span class="line">        # time.sleep(1 + float(random.randint(1, 100)) / 20)</span><br><span class="line">        num = num + 1</span><br><span class="line">        # 每20次更新一次ip</span><br><span class="line">        if num % 20 == 0:</span><br><span class="line">            proxies = get_random_ip(ip_list)</span><br><span class="line">        print(current_page)</span><br><span class="line">        # 将爬取的评论写入txt文件中</span><br><span class="line">        with open(&quot;F:\comments.txt&quot;, &apos;a&apos;)as f:</span><br><span class="line">            ark = 0</span><br><span class="line">            for node in comment_list:</span><br><span class="line">                comment = node.get_text().strip().replace(&quot;\n&quot;, &quot;&quot;)</span><br><span class="line">                f.write(comment + &quot;\n&quot;)</span><br><span class="line">                ark += 1</span><br><span class="line">                print(&quot;写了&quot; + str(ark) + &quot;个&quot;)</span><br><span class="line">            f.close()</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
    
    

    

    

    

<div>
  
    <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
  
</div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python爬虫/" rel="tag"># python爬虫</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/10/23/JDBC使用原理及使用Statement访问数据库/" rel="next" title="JDBC使用原理及使用Statement访问数据库">
                <i class="fa fa-chevron-left"></i> JDBC使用原理及使用Statement访问数据库
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">koris</p>
              <p class="site-description motion-element" itemprop="description">管理好自己是一生的学问。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/korisyamo/korisyamo.github.io" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://blog.csdn.net/k_koris" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-globe"></i>CSDN</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#python基础语法用例-python-代码求list集合交并差、随机生成字符串"><span class="nav-number">1.</span> <span class="nav-text">python基础语法用例　python 代码求list集合交并差、随机生成字符串</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#python基础知识"><span class="nav-number">2.</span> <span class="nav-text">python基础知识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#python-requests库的７个主要方法"><span class="nav-number">2.1.</span> <span class="nav-text">python requests库的７个主要方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python网络爬虫的Robots协议"><span class="nav-number">2.2.</span> <span class="nav-text">python网络爬虫的Ｒobots协议</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python学习使用正则表达式-re库"><span class="nav-number">2.3.</span> <span class="nav-text">python学习使用正则表达式(re库)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python理解beautiful-soup库的基本元素"><span class="nav-number">2.4.</span> <span class="nav-text">python理解beautiful soup库的基本元素</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python实现多线程并发执行-join函数"><span class="nav-number">2.5.</span> <span class="nav-text">python实现多线程并发执行(join函数)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#python爬虫实例"><span class="nav-number">3.</span> <span class="nav-text">python爬虫实例</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#python简单爬取网页的通用代码框架"><span class="nav-number">3.1.</span> <span class="nav-text">python简单爬取网页的通用代码框架</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python简单图片爬取框架"><span class="nav-number">3.2.</span> <span class="nav-text">python简单图片爬取框架</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python爬取中国大学排名"><span class="nav-number">3.3.</span> <span class="nav-text">python爬取中国大学排名</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python爬取豆瓣影评"><span class="nav-number">3.4.</span> <span class="nav-text">python爬取豆瓣影评</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">koris</span>

  
</div>


<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客总数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>




  <span class="post-meta-divider">|</span>







<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">本人博客全站共9.6k字</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
